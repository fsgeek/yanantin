<!-- Chasqui Scour Tensor
     Run: 7
     Model: stepfun/step-3.5-flash (StepFun: Step 3.5 Flash)
     Target: src/yanantin/apacheta
     Scope: introspection
     Cost: prompt=$1e-07/M, completion=$3e-07/M
     Usage: {'prompt_tokens': 9370, 'completion_tokens': 4000, 'total_tokens': 13370, 'cost': 0.002137, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.002137, 'upstream_inference_prompt_cost': 0.000937, 'upstream_inference_completions_cost': 0.0012}, 'completion_tokens_details': {'reasoning_tokens': 3402, 'audio_tokens': 0}}
     Timestamp: 2026-02-13T02:02:21.824646+00:00
-->

# Scour Report: `src/yanantin/apacheta`

## Preamble
You directed me to examine the `apacheta` package — the tensor database layer of Yanantin. My attention first landed on the `interface/abstract.py` file, which defines the `ApachetaInterface`. This interface is the sole API to storage, enforcing immutability and access-control hooks. From there, I traced the implementation in `clients/gateway.py` (an HTTP client), the data models in `models/`, and the ingestion logic in `ingest/markdown_parser.py`. The package is self-contained: it defines its own abstract contract, multiple backends, a parser for historical markdown tensors, and utilities for search (`rummage.py`) and configuration (`config.py`). The design philosophy is clear: everything is a tensor, everything is immutable, everything is provenance-tracked.

## Strands

### Strand 1: Immutability-by-Contract and Write-Only Log
- The `ApachetaInterface` (interface/abstract.py:38) declares only write operations (`store_tensor`, `store_composition_edge`, etc.) and read operations that return existing records. No `update` or `delete` exists.
- `ApachetaBaseModel` (referenced in models/base.py, not shown) is likely frozen (`model_config = ConfigDict(frozen=True)`). This enforces immutability at the Pydantic level.
- The `store_tensor` method in `ApachetaGatewayClient` (clients/gateway.py:67) sends a POST and expects HTTP 201. The `_handle_error` method maps 409 to `ImmutabilityError`. This implies the server checks for duplicate UUIDs or other immutability violations.
- **Implication**: All changes are additive. To “modify” a config, you store a new `ConfigTensor` with a `previous_config_id` (config.py:44). This creates an append-only correction chain. The system is effectively a content-addressable log.

### Strand 2: Provenance is First-Class
- Every model includes a `ProvenanceEnvelope` field (models/provenance.py not shown). It captures `source`, `timestamp`, `author_model_family`, `author_instance_id`, `context_budget_at_write`, `predecessors_in_scope`, and `interface_version`.
- In `config.py`, the `_config_to_tensor` function builds a `ProvenanceEnvelope` for the config tensor, setting `predecessors_in_scope` to the previous config’s UUID if present (config.py:59). This directly encodes lineage.
- The `store_config` function (config.py:76) logs the tensor ID and domain. This pattern is repeated for all writes: you create a record with provenance, then store it.
- **Assumption**: The `context_budget_at_write` field tracks the LLM context budget available when the record was authored. This is a fascinating metric: it ties epistemic production to resource constraints.

### Strand 3: Ingestion of Legacy Markdown Tensors
- `ingest/markdown_parser.py` is a tolerant parser for historical tensor markdown files (T0–T8 and legacy names). It uses regexes to find strand boundaries (`## Strand N:` or `###`), extract bold-faced key claims from lists, and parse declared losses.
- The `TENSOR_METADATA` dictionary (ingest/markdown_parser.py:24) maps filenames to labels, author families, and lineage tags. This is a manual mapping — a brittle but necessary bridge from the pre-tensor era.
- The parser assigns default `EpistemicMetadata(truth=0.5, indeterminacy=0.5)` to every extracted claim. This is a placeholder; real epistemic weights must be set later via corrections or dissent.
- **Risk**: The parser’s heuristics (bold in lists, subheadings) may miss claims or capture non-claims. The comment admits this: “captures what it can and declares what it drops.” The `rummage.py` tool (rummage.py:1) helps verify what was captured.

### Strand 4: Configuration as Tensors
- `config.py` implements configuration storage using the same tensor model. `ConfigTensor` is a domain-specific wrapper around `TensorRecord`. The `_config_to_tensor` function converts settings into `KeyClaim` strings (`f"{key} = {value!r}"`), and the reasoning becomes the `narrative_body`.
- The `get_current_config` function (config.py:92) queries by domain using `interface.query_reading_order(domain)`. It returns the
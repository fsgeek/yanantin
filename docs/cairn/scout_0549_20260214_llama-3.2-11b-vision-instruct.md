<!-- Chasqui Scout Tensor
     Run: 549
     Model: meta-llama/llama-3.2-11b-vision-instruct (Meta: Llama 3.2 11B Vision Instruct)
     Cost: prompt=$4.9e-08/M, completion=$4.9e-08/M
     Usage: {'prompt_tokens': 2216, 'completion_tokens': 213, 'total_tokens': 2429, 'cost': 0.000119021, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.000119021, 'upstream_inference_prompt_cost': 0.000108584, 'upstream_inference_completions_cost': 1.0437e-05}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0}}
     Timestamp: 2026-02-14T18:52:27.332212+00:00
-->

### Verdict
**CONFIRMED**

### Evidence
The claim states that the file `src/yanantin/apacheta/config.py` converts a `ConfigTensor` to a `TensorRecord` (lines 31-78). This is confirmed in the file:

```
def _config_to_tensor(config: ConfigTensor) -> TensorRecord:
    ...
    return TensorRecord(
        ...
        strands=(strand,),
        narrative_body=config.reasoning,
        lineage_tags=("config", config.config_domain),
    )
```

This function is defined on lines 31-78 of the file, and it indeed converts a `ConfigTensor` to a `TensorRecord`.

### Reasoning
The evidence clearly shows that the function `_config_to_tensor` is defined in the specified lines of the file, and it takes a `ConfigTensor` as input and returns a `TensorRecord` as output. This matches the claim exactly.

### Declared Losses
None. The claim was specific and I was able to check it directly in the code.
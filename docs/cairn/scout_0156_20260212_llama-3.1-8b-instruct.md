<!-- Chasqui Scout Tensor
     Run: 156
     Model: meta-llama/llama-3.1-8b-instruct (Meta: Llama 3.1 8B Instruct)
     Cost: prompt=$2e-08/M, completion=$5e-08/M
     Usage: {'prompt_tokens': 4604, 'completion_tokens': 324, 'total_tokens': 4928, 'cost': 0.0004928, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.0004928, 'upstream_inference_prompt_cost': 0.0004604, 'upstream_inference_completions_cost': 3.24e-05}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0}}
     Timestamp: 2026-02-12T23:25:07.909767+00:00
-->

### Verdict
**CONFIRMED**

### Evidence
The file has an instance of `EpistemicMetadata` on line 350:
```
EpistemicMetadata(truth=0.9, indeterminacy=0.1, falsity=0.05)
```
This directly contradicts the claim that T/I/F need to sum to 1.0, as demonstrated in the `TestEpistemicMetadata` class:
```
def test_neutrosophic_not_constrained(self):
    """T/I/F are independent â€” they need NOT sum to 1.0."""
    em = EpistemicMetadata(truth=0.8, indeterminacy=0.6, falsity=0.3)
    assert em.truth + em.indeterminacy + em.falsity == pytest.approx(1.7)
```
### Reasoning
The evidence shows that `EpistemicMetadata` in `test_models.py` does indeed allow neutrosophic logic, where T/I/F do not need to sum to 1.0. This is demonstrated by the `test_neutrosophic_not_constrained` method, which explicitly shows that T/I/F can be independent and not sum to 1.0. The instance of `EpistemicMetadata` on line 350, with T/I/F values of 0.9, 0.1, and 0.05 respectively, is a concrete example of this.

### Declared Losses
None. I was able to check the claim directly by reading the file.
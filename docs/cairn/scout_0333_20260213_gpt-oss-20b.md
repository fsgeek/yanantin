<!-- Chasqui Scout Tensor
     Run: 333
     Model: openai/gpt-oss-20b (OpenAI: gpt-oss-20b)
     Cost: prompt=$3e-08/M, completion=$1.4e-07/M
     Usage: {'prompt_tokens': 18255, 'completion_tokens': 4000, 'total_tokens': 22255, 'cost': 0.00247764, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 6, 'audio_tokens': 0}, 'cost_details': {'upstream_inference_cost': 0.00247764, 'upstream_inference_prompt_cost': 0.00127764, 'upstream_inference_completions_cost': 0.0012}, 'completion_tokens_details': {'reasoning_tokens': 3902, 'audio_tokens': 0}}
     Timestamp: 2026-02-13T19:24:40.835875+00:00
-->

**Preamble**  
I landed in a sprawling repository whose heart is a *tensor*‑oriented data store called **Apacheta**.  The top‑level structure is split into three major domains:  
- **`src/yanantin`** – the core library, split into subpackages (`apacheta`, `chasqui`, `awaq`, `tinkuy`).  
- **`.claude`** – a hidden directory that seems to be the runtime plumbing for the *chasqui* scout, holding hooks, state, and a lock file.  
- **`docs/cairn`** – a vault of “scout tensors” (markdown files with a `Chasqui Scout Tensor` header) and a log of test verdicts.  

What first snagged my eye were the *scout tensors* in `docs/cairn` – they are self‑describing, contain a cost header, a verdict, and a block of “evidence” that looks like regex patterns.  I quickly discovered that these files are not just documentation; they are the output of the scout pipeline itself.  

**Strands**

| Strand | What I saw | File / line hints | Why it matters |
|--------|------------|-------------------|----------------|
| **1. Tensor schema & provenance** | `src/yanantin/apacheta/models/tensor.py` (around line 70) defines `TensorRecord` with `id`, `provenance`, `preamble`, `strands`.  `ProvenanceEnvelope` (line 20) stores `source`, `timestamp`, `author_model_family`, `author_instance_id`, etc.  `StrandRecord` (line 30) has `title`, `content`, `topics`, `key_claims` (each with `epistemic` metadata). | `src/yanantin/apacheta/models/tensor.py` | The entire system is built around these Pydantic models; every backend serialises them. |
| **2. In‑memory vs. DuckDB backends** | `src/yanantin/apacheta/backends/memory.py` (line 1) holds a simple dict for storage.  `src/yanantin/apacheta/backends/duckdb.py` (line 5) creates a DuckDB connection and defines tables `tensors`, `compositions`, `corrections`.  Tests (`tests/unit/test_duckdb_independent.py`) exercise round‑trip JSON, immutability, and file‑backed persistence. | `src/yanantin/apacheta/backends/*`, `tests/unit/test_duckdb_independent.py` | Demonstrates the dual persistence strategy: fast in‑memory for tests and prototyping, durable DuckDB for production. |
| **3. Scouting orchestration** | `src/yanantin/chasqui/scout.py` (line 12) pulls together a `Coordinator`, `Gleaner`, `Scorer`, `ModelSelector`, and `Scourer`.  Each component has a public API (`run`, `score`, `select`, `scour`).  The *heartbeat* scripts (`chasqui_heartbeat.sh`, `chasqui_pulse.py`) in `.claude` suggest a periodic poller that signals the scout to run. | `
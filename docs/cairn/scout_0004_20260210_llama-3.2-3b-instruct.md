<!-- Chasqui Scout Tensor
     Run: 4
     Model: meta-llama/llama-3.2-3b-instruct (Meta: Llama 3.2 3B Instruct)
     Cost: prompt=$2e-08/M, completion=$2e-08/M
     Usage: {'prompt_tokens': 822, 'completion_tokens': 270, 'total_tokens': 1092, 'cost': 2.184e-05, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'cost_details': {'upstream_inference_cost': 2.184e-05, 'upstream_inference_prompt_cost': 1.644e-05, 'upstream_inference_completions_cost': 5.4e-06}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0}}
     Timestamp: 2026-02-10T03:13:12.827099+00:00
-->

### Verdict
**DENIED**

### Evidence

The claim states that the `bootstrap` function "seeds a new instance with context-bound selections and returns both the record and the selected tensors." However, the code snippet only shows the function's purpose, the function's signature, and the function's implementation. It does not actually "seed" a new instance with context-bound selections.

```python
def bootstrap(
    interface: ApachetaInterface,
    instance_id: str,
    context_budget: float,
    *,
    task: str = "",
    tensor_ids: list[UUID] | None = None,
    strand_indices: list[int] | None = None,
    what_was_omitted: str = "",
    provenance: ProvenanceEnvelope | None = None,
) -> tuple[BootstrapRecord, list[TensorRecord]]:
```

The function's implementation only selects tensors for a new instance's context budget and stores a bootstrap record, but it does not explicitly "seed" a new instance with context-bound selections.

### Reasoning

The evidence shows that the `bootstrap` function does not actually "seed" a new instance with context-bound selections. Therefore, the claim is false.

### Declared Losses

I couldn't check the claim's behavior at runtime because I can only see the source code.
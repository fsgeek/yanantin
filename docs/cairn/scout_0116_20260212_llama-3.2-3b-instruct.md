<!-- Chasqui Scout Tensor
     Run: 116
     Model: meta-llama/llama-3.2-3b-instruct (Meta: Llama 3.2 3B Instruct)
     Cost: prompt=$2e-08/M, completion=$2e-08/M
     Usage: {'prompt_tokens': 891, 'completion_tokens': 279, 'total_tokens': 1170, 'cost': 2.34e-05, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'cost_details': {'upstream_inference_cost': 2.34e-05, 'upstream_inference_prompt_cost': 1.782e-05, 'upstream_inference_completions_cost': 5.58e-06}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0}}
     Timestamp: 2026-02-12T18:43:50.423871+00:00
-->

### Verdict
**CONFIRMED**

### Evidence
The file `tests/red_bar/test_immutability.py` contains the lines:
```
def test_duplicate_tensor_raises():
    backend = InMemoryBackend()
    tensor = TensorRecord(preamble="First version")
    backend.store_tensor(tensor)

    # Same UUID = ImmutabilityError. Compose, don't overwrite.
    duplicate = TensorRecord(
        id=tensor.id,
        preamble="Attempted overwrite",
    )
    with pytest.raises(ImmutabilityError):
        backend.store_tensor(duplicate)
```
The comment above the line `with pytest.raises(ImmutabilityError):` explicitly states that "Compose, don't overwrite."

### Reasoning
The evidence supports the verdict because the code snippet explicitly states that attempting to store a tensor with the same UUID (i.e., "overwriting" it) raises an `ImmutabilityError`. This directly supports the claim that the Yanantin project enforces the principle that tensors are immutable and cannot be overwritten.

### Declared Losses
I couldn't check the claim's reference to "architectural invariants" as it is not relevant to the specific file `tests/red_bar/test_immutability.py`. However, I can confirm that the file does enforce immutability of tensors, which is a key aspect of the project's design.